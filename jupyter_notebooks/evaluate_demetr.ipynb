{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b284fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b1406",
   "metadata": {},
   "source": [
    "'source': a string containing the text that needs to be translated     \n",
    "'good-translation': possible translation of the source sentence     \n",
    "'incorrect-translation': translation of the source sentence that contains an error or phenomenon of interest     \n",
    "'reference': the gold standard translation     \n",
    "'phenomena': the type of error or phenomena being studied in the example     \n",
    "'langpair': the source language and the target language pair of the example     \n",
    "Note that the good-translation may not be free of errors but it is a better translation than the incorrect-translation     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e1ab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>good_translation</th>\n",
       "      <th>incorrect_translation</th>\n",
       "      <th>severity</th>\n",
       "      <th>phenomena</th>\n",
       "      <th>langpair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在食用受污染宠物食品后死亡的宠物的尿样中，均发现了氰尿酸和三聚氰胺。</td>\n",
       "      <td>Both cyanuric acid and melamine were found in ...</td>\n",
       "      <td>Cyanuric acid and melamine were both found in ...</td>\n",
       "      <td>Cyanuric acid and melamine were both in found ...</td>\n",
       "      <td>minor</td>\n",
       "      <td>two adjacent word swaps</td>\n",
       "      <td>chinese_simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>通过红外光谱 (FTIR) 进行比较后发现，这些结晶的成分与在受影响宠物的尿液中发现的结晶成...</td>\n",
       "      <td>The composition of these crystals matches thos...</td>\n",
       "      <td>A comparison by infrared spectroscopy (FTIR) r...</td>\n",
       "      <td>A comparison by infrared spectroscopy (FTIR) r...</td>\n",
       "      <td>minor</td>\n",
       "      <td>two adjacent word swaps</td>\n",
       "      <td>chinese_simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我不知道你有没有意识到，从中美洲进口到这个国家的大部分货物都是免关税的。</td>\n",
       "      <td>I don't know if you realize it or not, but mos...</td>\n",
       "      <td>I don't know if you realize that most of the g...</td>\n",
       "      <td>I don't know if you realize that most of the g...</td>\n",
       "      <td>minor</td>\n",
       "      <td>two adjacent word swaps</td>\n",
       "      <td>chinese_simple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0                 在食用受污染宠物食品后死亡的宠物的尿样中，均发现了氰尿酸和三聚氰胺。   \n",
       "1  通过红外光谱 (FTIR) 进行比较后发现，这些结晶的成分与在受影响宠物的尿液中发现的结晶成...   \n",
       "2               我不知道你有没有意识到，从中美洲进口到这个国家的大部分货物都是免关税的。   \n",
       "\n",
       "                                                 ref  \\\n",
       "0  Both cyanuric acid and melamine were found in ...   \n",
       "1  The composition of these crystals matches thos...   \n",
       "2  I don't know if you realize it or not, but mos...   \n",
       "\n",
       "                                    good_translation  \\\n",
       "0  Cyanuric acid and melamine were both found in ...   \n",
       "1  A comparison by infrared spectroscopy (FTIR) r...   \n",
       "2  I don't know if you realize that most of the g...   \n",
       "\n",
       "                               incorrect_translation severity  \\\n",
       "0  Cyanuric acid and melamine were both in found ...    minor   \n",
       "1  A comparison by infrared spectroscopy (FTIR) r...    minor   \n",
       "2  I don't know if you realize that most of the g...    minor   \n",
       "\n",
       "                 phenomena        langpair  \n",
       "0  two adjacent word swaps  chinese_simple  \n",
       "1  two adjacent word swaps  chinese_simple  \n",
       "2  two adjacent word swaps  chinese_simple  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify your home path\n",
    "home_path = '/home/glushkovato/robustness'\n",
    "\n",
    "path = home_path + '/robust_MT_evaluation/data/test/robustness/demetr.csv'\n",
    "demetr = pd.read_csv(path)\n",
    "demetr.columns = ['src', 'ref', 'good_translation', 'incorrect_translation', 'severity', 'phenomena', 'langpair']\n",
    "demetr.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19146f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['changing a word to its antonym (noun, adv, adj, verb)',\n",
       "       'affirmative to negation and negation to affirmative', 'codemix',\n",
       "       'remove noun which is not the sentence subject (head)',\n",
       "       'removes content verb',\n",
       "       'shuffled words keeping the sentence features (capitalization, punctuation)',\n",
       "       'adding a word that does not break the grammaticality of the sentence but which affects the meaning in a significant way',\n",
       "       'removes adj or adv', 'remove the head of the subject NP',\n",
       "       'change of gender pronoun (e.g., \"he\" to \"she\")',\n",
       "       'remove random named entity',\n",
       "       'numbers changed in a reasonable range',\n",
       "       'replace NE with a regard to the entity type (e.g., PER for PER)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical = demetr[demetr.severity == 'critical']\n",
    "critical.phenomena.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842455a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "demetr.incorrect_translation = demetr.incorrect_translation.apply(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2a3c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30320, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demetr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd7799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_source.txt\", \"w\") as f:\n",
    "    for i in demetr.src.tolist():\n",
    "        print(i, file=f)\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_good_translation.txt\", \"w\") as f:\n",
    "    for i in demetr.good_translation.tolist():\n",
    "        print(i, file=f)\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_bad_translation.txt\", \"w\") as f:\n",
    "    for i in demetr.incorrect_translation.tolist():\n",
    "        print(i.replace('\\n', ' '), file=f)\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_reference.txt\", \"w\") as f:\n",
    "    for i in demetr.ref.tolist():\n",
    "        print(i, file=f)\n",
    "        \n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_phenomena.txt\", \"w\") as f:\n",
    "    for i in demetr.phenomena.tolist():\n",
    "        print(i, file=f)\n",
    "        \n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_lp.txt\", \"w\") as f:\n",
    "    for i in demetr.langpair.tolist():\n",
    "        print(i, file=f)\n",
    "        \n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_severity.txt\", \"w\") as f:\n",
    "    for i in demetr.severity.tolist():\n",
    "        print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    f = open (path, \"r\")\n",
    "    data = json.loads(f.read())\n",
    "    k = list(data.keys())[0]\n",
    "\n",
    "    src = []\n",
    "    mt = []\n",
    "    ref = []\n",
    "    COMET_score = []\n",
    "\n",
    "    for i in data[k]:\n",
    "        src.append(i['src'])\n",
    "        mt.append(i['mt'])\n",
    "        ref.append(i['ref'])\n",
    "        COMET_score.append(float(i['COMET']))\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    df = pd.DataFrame(data=np.array([src, mt, ref, COMET_score]).T, \n",
    "                      columns=['src', 'mt', 'ref', 'comet'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1622e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_kendall_tau_like(df):\n",
    "#     '''\n",
    "#     Compute correlation as Kendall Tau-like scores.\n",
    "#     '''\n",
    "#     concordant = (df.comet_good > df.comet_bad).sum()\n",
    "#     discordant = (df.comet_good <= df.comet_bad).sum()\n",
    "#     t = (concordant - discordant)/(concordant + discordant)\n",
    "#     return np.round(t, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e141db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(good_metric, bad_metric):\n",
    "    acc = (good_metric > bad_metric).sum()/len(good_metric)\n",
    "    return np.round(acc*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a704547",
   "metadata": {},
   "source": [
    "## compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d953c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ['24e1', '25e1', '29e1', '83e1']\n",
    "# 24 comet\n",
    "# 25 comet + aug\n",
    "# 29 comet + sl-features bottleneck-64 \n",
    "# 83 word-level sum\n",
    "\n",
    "\n",
    "# read bleu and chrf\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_scores_bleu.txt\", \"r\") as f:\n",
    "    good_bleu = [float(i) for i in f]\n",
    "    \n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_scores_bleu.txt\", \"r\") as f:\n",
    "    bad_bleu = [float(i) for i in f]\n",
    "    \n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_scores_chrf.txt\", \"r\") as f:\n",
    "    good_chrf = [float(i) for i in f]\n",
    "    \n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_scores_chrf.txt\", \"r\") as f:\n",
    "    bad_chrf = [float(i) for i in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a179fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demetr['bleu_good'] = good_bleu\n",
    "demetr['bleu_bad'] = bad_bleu\n",
    "\n",
    "demetr['chrf_good'] = good_chrf\n",
    "demetr['chrf_bad'] = bad_chrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3fbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_good = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_output_v24e1.json'\n",
    "path_bad = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_output_v24e1.json'\n",
    "good_tmp = read_json(path_good)\n",
    "bad_tmp = read_json(path_bad)\n",
    "demetr['comet_good_v24e1'] = good_tmp.comet.tolist()\n",
    "demetr['comet_bad_v24e1'] = bad_tmp.comet.tolist()\n",
    "\n",
    "path_good = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_output_v25e1.json'\n",
    "path_bad = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_output_v25e1.json'\n",
    "good_tmp = read_json(path_good)\n",
    "bad_tmp = read_json(path_bad)\n",
    "demetr['comet_good_v25e1'] = good_tmp.comet.tolist()\n",
    "demetr['comet_bad_v25e1'] = bad_tmp.comet.tolist()\n",
    "\n",
    "path_good = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_output_v29e1.json'\n",
    "path_bad = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_output_v29e1.json'\n",
    "good_tmp = read_json(path_good)\n",
    "bad_tmp = read_json(path_bad)\n",
    "demetr['comet_good_v29e1'] = good_tmp.comet.tolist()\n",
    "demetr['comet_bad_v29e1'] = bad_tmp.comet.tolist()\n",
    "\n",
    "path_good = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_output_v83e1.json'\n",
    "path_bad = home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_output_v83e1.json'\n",
    "good_tmp = read_json(path_good)\n",
    "bad_tmp = read_json(path_bad)\n",
    "demetr['comet_good_v83e1'] = good_tmp.comet.tolist()\n",
    "demetr['comet_bad_v83e1'] = bad_tmp.comet.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff4c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    x = (x - mean)/std\n",
    "    return np.nan_to_num(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be44de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    return [mean, std]\n",
    "\n",
    "def apply_norm(mean, std, x):\n",
    "    xn = (np.array(x) - mean)/std\n",
    "    return np.array(xn)\n",
    "\n",
    "\n",
    "bleu_mean = 28.759837809513634\n",
    "bleu_std = 18.47107097319373\n",
    "chrf_mean = 58.992697061544284\n",
    "chrf_std = 14.286372518233168\n",
    "comet_mean = 0.46782439675103793\n",
    "comet_std = 0.37521584265953595\n",
    "\n",
    "# true_scores = all_mqm\n",
    "# scores_bleu = apply_norm(bleu_mean, bleu_std, all_bleu)\n",
    "# scores_chrf = apply_norm(chrf_mean, chrf_std, all_chrf)\n",
    "# scores_comet = apply_norm(comet_mean, comet_std, all_comet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e967102b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 96.87, 92.91, 93.77, 95.14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble scores\n",
    "\n",
    "# best weights based on kendall - computed over mqm 2021\n",
    "a = 0.02512562814070352\n",
    "b = 0.04522613065326633\n",
    "c = 0.9296482412060302\n",
    "\n",
    "demetr['ensemble_good'] = np.mean([a*apply_norm(bleu_mean, bleu_std, demetr.bleu_good.tolist()),\n",
    "                                   b*apply_norm(chrf_mean, chrf_std, demetr.chrf_good.tolist()), \n",
    "                                   c*apply_norm(comet_mean, comet_std, demetr.comet_good_v24e1.astype('float').tolist())], axis=0)\n",
    "\n",
    "demetr['ensemble_bad'] = np.mean([a*apply_norm(bleu_mean, bleu_std, demetr.bleu_bad.tolist()),\n",
    "                                  b*apply_norm(chrf_mean, chrf_std, demetr.chrf_bad.tolist()),\n",
    "                                  c*apply_norm(comet_mean, comet_std, demetr.comet_bad_v24e1.astype('float').tolist())], axis=0)\n",
    "\n",
    "demetr_minor = demetr[demetr.severity == 'minor']\n",
    "acc_ensemble_minor = compute_acc(demetr_minor.ensemble_good, demetr_minor.ensemble_bad)\n",
    "\n",
    "demetr_major = demetr[demetr.severity == 'major']\n",
    "acc_ensemble_major = compute_acc(demetr_major.ensemble_good, demetr_major.ensemble_bad)\n",
    "\n",
    "demetr_critical = demetr[demetr.severity == 'critical']\n",
    "acc_ensemble_critical = compute_acc(demetr_critical.ensemble_good, demetr_critical.ensemble_bad)\n",
    "\n",
    "demetr_base = demetr[demetr.severity == 'base']\n",
    "acc_ensemble_base = compute_acc(demetr_base.ensemble_good, demetr_base.ensemble_bad)\n",
    "\n",
    "acc_ensemble_all = compute_acc(demetr.ensemble_good, demetr.ensemble_bad)\n",
    "\n",
    "acc_ensemble_base, acc_ensemble_critical, acc_ensemble_major, acc_ensemble_minor, acc_ensemble_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671c73a",
   "metadata": {},
   "source": [
    "## compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cc938f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minor :  72.6 80.83 92.18 92.06 94.64 96.36\n",
      "major :  83.76 90.85 91.04 91.66 93.56 93.9\n",
      "critical :  79.33 90.79 95.77 95.54 96.95 96.48\n",
      "base :  100.0 100.0 99.3 98.6 99.3 99.2\n"
     ]
    }
   ],
   "source": [
    "# bleu\n",
    "# chrf\n",
    "# 24 comet\n",
    "# 25 comet + aug\n",
    "# 29 sl bottleneck-64 \n",
    "# 83 word-level sum\n",
    "\n",
    "severities = ['minor', 'major', 'critical', 'base']\n",
    "\n",
    "for s in severities:\n",
    "    demetr_minor = demetr[demetr.severity == s]\n",
    "    acc_bleu = compute_acc(demetr_minor.bleu_good, demetr_minor.bleu_bad)\n",
    "    acc_chrf = compute_acc(demetr_minor.chrf_good, demetr_minor.chrf_bad)\n",
    "    acc_comet_good_v24e1 = compute_acc(demetr_minor.comet_good_v24e1, demetr_minor.comet_bad_v24e1)\n",
    "    acc_comet_good_v25e1 = compute_acc(demetr_minor.comet_good_v25e1, demetr_minor.comet_bad_v25e1)\n",
    "    acc_comet_good_v29e1 = compute_acc(demetr_minor.comet_good_v29e1, demetr_minor.comet_bad_v29e1)\n",
    "    acc_comet_good_v83e1 = compute_acc(demetr_minor.comet_good_v83e1, demetr_minor.comet_bad_v83e1)\n",
    "\n",
    "\n",
    "    print(s , ': ', acc_bleu, acc_chrf, acc_comet_good_v24e1, acc_comet_good_v25e1, \n",
    "          acc_comet_good_v29e1, acc_comet_good_v83e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2108a505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.52, 87.16, 93.74, 93.65, 95.59, 96.2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all acc\n",
    "acc_bleu = compute_acc(demetr.bleu_good, demetr.bleu_bad)\n",
    "acc_chrf = compute_acc(demetr.chrf_good, demetr.chrf_bad)\n",
    "acc_comet_good_v24e1 = compute_acc(demetr.comet_good_v24e1, demetr.comet_bad_v24e1)\n",
    "acc_comet_good_v25e1 = compute_acc(demetr.comet_good_v25e1, demetr.comet_bad_v25e1)\n",
    "acc_comet_good_v29e1 = compute_acc(demetr.comet_good_v29e1, demetr.comet_bad_v29e1)\n",
    "acc_comet_good_v83e1 = compute_acc(demetr.comet_good_v83e1, demetr.comet_bad_v83e1)\n",
    "\n",
    "acc_bleu, acc_chrf, acc_comet_good_v24e1, acc_comet_good_v25e1, acc_comet_good_v29e1, acc_comet_good_v83e1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e310d3",
   "metadata": {},
   "source": [
    "## compute kendall tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71d35b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kendall_tau_like(comet_good, comet_bad):\n",
    "    '''\n",
    "    Compute correlation as Kendall Tau-like scores.\n",
    "    '''\n",
    "    concordant = (comet_good > comet_bad).sum()\n",
    "    discordant = (comet_good <= comet_bad).sum()\n",
    "    t = (concordant - discordant)/(concordant + discordant)\n",
    "    return np.round(t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d36932f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp:  chinese_simple\n",
      "0.505\n",
      "0.684\n",
      "0.818\n",
      "0.855\n",
      "0.817\n",
      "0.866\n",
      "0.872\n",
      "lp:  german\n",
      "0.655\n",
      "0.802\n",
      "0.909\n",
      "0.926\n",
      "0.917\n",
      "0.942\n",
      "0.957\n",
      "lp:  hindi\n",
      "0.616\n",
      "0.768\n",
      "0.9\n",
      "0.92\n",
      "0.925\n",
      "0.929\n",
      "0.945\n",
      "lp:  japanese\n",
      "0.521\n",
      "0.722\n",
      "0.85\n",
      "0.883\n",
      "0.83\n",
      "0.907\n",
      "0.891\n",
      "lp:  polish\n",
      "0.533\n",
      "0.703\n",
      "0.818\n",
      "0.88\n",
      "0.775\n",
      "0.863\n",
      "0.877\n",
      "lp:  russian\n",
      "0.552\n",
      "0.724\n",
      "0.898\n",
      "0.91\n",
      "0.894\n",
      "0.95\n",
      "0.949\n",
      "lp:  czech\n",
      "0.541\n",
      "0.755\n",
      "0.875\n",
      "0.917\n",
      "0.863\n",
      "0.87\n",
      "0.92\n",
      "lp:  french\n",
      "0.664\n",
      "0.794\n",
      "0.892\n",
      "0.915\n",
      "0.926\n",
      "0.945\n",
      "0.951\n",
      "lp:  spanish\n",
      "0.516\n",
      "0.704\n",
      "0.877\n",
      "0.899\n",
      "0.877\n",
      "0.912\n",
      "0.935\n",
      "lp:  italian\n",
      "0.601\n",
      "0.774\n",
      "0.912\n",
      "0.924\n",
      "0.906\n",
      "0.936\n",
      "0.945\n",
      "avg bleu:  0.57\n",
      "avg chrf:  0.743\n",
      "avg v24e1:  0.875\n",
      "avg ensemble:  0.903\n",
      "avg v25e1:  0.873\n",
      "avg v29e1:  0.912\n",
      "avg v83e1:  0.924\n"
     ]
    }
   ],
   "source": [
    "all_t_bleu = []\n",
    "all_t_chrf = []\n",
    "all_t_v24e1 = []\n",
    "all_t_v25e1 = []\n",
    "all_t_v29e1 = []\n",
    "all_t_v83e1 = []\n",
    "all_t_ensemble = []\n",
    "\n",
    "lps = demetr.langpair.unique()\n",
    "for lp in lps:\n",
    "    print('lp: ', lp)\n",
    "    df_lp = demetr[demetr.langpair == lp]\n",
    "    t_ensemble = compute_kendall_tau_like(df_lp.ensemble_good, df_lp.ensemble_bad)\n",
    "    t_bleu = compute_kendall_tau_like(df_lp.bleu_good, df_lp.bleu_bad)\n",
    "    t_chrf = compute_kendall_tau_like(df_lp.chrf_good, df_lp.chrf_bad)\n",
    "    t_v24e1 = compute_kendall_tau_like(df_lp.comet_good_v24e1, df_lp.comet_bad_v24e1)\n",
    "    t_v25e1 = compute_kendall_tau_like(df_lp.comet_good_v25e1, df_lp.comet_bad_v25e1)\n",
    "    t_v29e1 = compute_kendall_tau_like(df_lp.comet_good_v29e1, df_lp.comet_bad_v29e1)\n",
    "    t_v83e1 = compute_kendall_tau_like(df_lp.comet_good_v83e1, df_lp.comet_bad_v83e1)\n",
    "    \n",
    "    print(np.round(np.mean(t_bleu), 3))\n",
    "    print(np.round(np.mean(t_chrf), 3))\n",
    "    print(np.round(np.mean(t_v24e1), 3))\n",
    "    print(np.round(np.mean(t_ensemble), 3))\n",
    "    print(np.round(np.mean(t_v25e1), 3))\n",
    "    print(np.round(np.mean(t_v29e1), 3))\n",
    "    print(np.round(np.mean(t_v83e1), 3))\n",
    "    \n",
    "    all_t_bleu.append(t_bleu)\n",
    "    all_t_chrf.append(t_chrf)\n",
    "    all_t_v24e1.append(t_v24e1)\n",
    "    all_t_ensemble.append(t_ensemble)\n",
    "    all_t_v25e1.append(t_v25e1)\n",
    "    all_t_v29e1.append(t_v29e1)\n",
    "    all_t_v83e1.append(t_v83e1)\n",
    "\n",
    "print('avg bleu: ', np.round(np.mean(all_t_bleu), 3))\n",
    "print('avg chrf: ', np.round(np.mean(all_t_chrf), 3))\n",
    "print('avg v24e1: ', np.round(np.mean(all_t_v24e1), 3))\n",
    "print('avg ensemble: ', np.round(np.mean(all_t_ensemble), 3))\n",
    "print('avg v25e1: ', np.round(np.mean(all_t_v25e1), 3))\n",
    "print('avg v29e1: ', np.round(np.mean(all_t_v29e1), 3))\n",
    "print('avg v83e1: ', np.round(np.mean(all_t_v83e1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9a2df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demetr.to_csv(home_path + '/robust_MT_evaluation/data/test/robustness/demetr_with_preds.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36295e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd334fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c1688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cb1e39d",
   "metadata": {},
   "source": [
    "## compute features for DEMETR: bleu and chrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd39f96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>good_translation</th>\n",
       "      <th>incorrect_translation</th>\n",
       "      <th>severity</th>\n",
       "      <th>phenomena</th>\n",
       "      <th>langpair</th>\n",
       "      <th>bleu_good</th>\n",
       "      <th>bleu_bad</th>\n",
       "      <th>chrf_good</th>\n",
       "      <th>...</th>\n",
       "      <th>comet_good_v24e1</th>\n",
       "      <th>comet_bad_v24e1</th>\n",
       "      <th>comet_good_v25e1</th>\n",
       "      <th>comet_bad_v25e1</th>\n",
       "      <th>comet_good_v29e1</th>\n",
       "      <th>comet_bad_v29e1</th>\n",
       "      <th>comet_good_v83e1</th>\n",
       "      <th>comet_bad_v83e1</th>\n",
       "      <th>ensemble_good</th>\n",
       "      <th>ensemble_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在食用受污染宠物食品后死亡的宠物的尿样中，均发现了氰尿酸和三聚氰胺。</td>\n",
       "      <td>Both cyanuric acid and melamine were found in ...</td>\n",
       "      <td>Cyanuric acid and melamine were both found in ...</td>\n",
       "      <td>Cyanuric acid and melamine were both in found ...</td>\n",
       "      <td>minor</td>\n",
       "      <td>two adjacent word swaps</td>\n",
       "      <td>chinese_simple</td>\n",
       "      <td>39.035944</td>\n",
       "      <td>30.143353</td>\n",
       "      <td>73.376263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8044230341911316</td>\n",
       "      <td>0.7144668102264404</td>\n",
       "      <td>0.964411199092865</td>\n",
       "      <td>0.8717182278633118</td>\n",
       "      <td>0.9330844283103943</td>\n",
       "      <td>0.6408037543296814</td>\n",
       "      <td>0.5853949189186096</td>\n",
       "      <td>0.40478262305259705</td>\n",
       "      <td>0.297827</td>\n",
       "      <td>0.215072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  src  \\\n",
       "0  在食用受污染宠物食品后死亡的宠物的尿样中，均发现了氰尿酸和三聚氰胺。   \n",
       "\n",
       "                                                 ref  \\\n",
       "0  Both cyanuric acid and melamine were found in ...   \n",
       "\n",
       "                                    good_translation  \\\n",
       "0  Cyanuric acid and melamine were both found in ...   \n",
       "\n",
       "                               incorrect_translation severity  \\\n",
       "0  Cyanuric acid and melamine were both in found ...    minor   \n",
       "\n",
       "                 phenomena        langpair  bleu_good   bleu_bad  chrf_good  \\\n",
       "0  two adjacent word swaps  chinese_simple  39.035944  30.143353  73.376263   \n",
       "\n",
       "   ...    comet_good_v24e1     comet_bad_v24e1   comet_good_v25e1  \\\n",
       "0  ...  0.8044230341911316  0.7144668102264404  0.964411199092865   \n",
       "\n",
       "      comet_bad_v25e1    comet_good_v29e1     comet_bad_v29e1  \\\n",
       "0  0.8717182278633118  0.9330844283103943  0.6408037543296814   \n",
       "\n",
       "     comet_good_v83e1      comet_bad_v83e1 ensemble_good  ensemble_bad  \n",
       "0  0.5853949189186096  0.40478262305259705      0.297827      0.215072  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demetr.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "13db7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 30320/30320 [00:07<00:00, 4041.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute bleu\n",
    "\n",
    "demetr_good_scores_bleu = []\n",
    "refs_demetr = demetr.ref.tolist()\n",
    "good_mts_demetr = demetr.good_translation.tolist()\n",
    "bad_mts_demetr = demetr.incorrect_translation.tolist()\n",
    "\n",
    "for i in tqdm(range(len(good_mts_demetr))):\n",
    "    demetr_good_scores_bleu.append(sacrebleu.sentence_bleu(good_mts_demetr[i], [refs_demetr[i]]))\n",
    "    \n",
    "demetr_good_scores_bleu = np.array([i.score for i in demetr_good_scores_bleu])\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_scores_bleu.txt\", \"w\") as f:\n",
    "    for i in demetr_good_scores_bleu:\n",
    "        print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3a196a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 30320/30320 [00:06<00:00, 4655.32it/s]\n"
     ]
    }
   ],
   "source": [
    "demetr_bad_scores_bleu = []\n",
    "for i in tqdm(range(len(bad_mts_demetr))):\n",
    "    demetr_bad_scores_bleu.append(sacrebleu.sentence_bleu(bad_mts_demetr[i], [refs_demetr[i]]))\n",
    "    \n",
    "demetr_bad_scores_bleu = np.array([i.score for i in demetr_bad_scores_bleu])\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_scores_bleu.txt\", \"w\") as f:\n",
    "    for i in demetr_bad_scores_bleu:\n",
    "        print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fc3eda0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 30320/30320 [00:10<00:00, 2848.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute chrf\n",
    "\n",
    "demetr_good_scores_chrf = []\n",
    "refs_demetr = demetr.ref.tolist()\n",
    "good_mts_demetr = demetr.good_translation.tolist()\n",
    "bad_mts_demetr = demetr.incorrect_translation.tolist()\n",
    "\n",
    "for i in tqdm(range(len(good_mts_demetr))):\n",
    "    demetr_good_scores_chrf.append(sacrebleu.sentence_chrf(good_mts_demetr[i], [refs_demetr[i]]))\n",
    "    \n",
    "demetr_good_scores_chrf = np.array([i.score for i in demetr_good_scores_chrf])\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_scores_chrf.txt\", \"w\") as f:\n",
    "    for i in demetr_good_scores_chrf:\n",
    "        print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9408772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 30320/30320 [00:10<00:00, 2959.39it/s]\n"
     ]
    }
   ],
   "source": [
    "demetr_bad_scores_chrf = []\n",
    "for i in tqdm(range(len(bad_mts_demetr))):\n",
    "    demetr_bad_scores_chrf.append(sacrebleu.sentence_chrf(bad_mts_demetr[i], [refs_demetr[i]]))\n",
    "    \n",
    "demetr_bad_scores_chrf = np.array([i.score for i in demetr_bad_scores_chrf])\n",
    "\n",
    "with open(home_path + \"/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_scores_chrf.txt\", \"w\") as f:\n",
    "    for i in demetr_bad_scores_chrf:\n",
    "        print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f9203625",
   "metadata": {},
   "outputs": [],
   "source": [
    "demetr_good_feats = pd.DataFrame(data=np.array([demetr_good_scores_bleu, demetr_good_scores_chrf]).T, columns=['f1', 'f2'])\n",
    "demetr_good_feats.to_csv(home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_good_features.csv', index=None, header=None)\n",
    "\n",
    "demetr_bad_feats = pd.DataFrame(data=np.array([demetr_bad_scores_bleu, demetr_bad_scores_chrf]).T, columns=['f1', 'f2'])\n",
    "demetr_bad_feats.to_csv(home_path + '/robust_MT_evaluation/data/test/robustness/demetr_predictions/demetr_bad_features.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f0b08744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.035944</td>\n",
       "      <td>73.376263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.427617</td>\n",
       "      <td>84.359787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.096580</td>\n",
       "      <td>71.701801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.581040</td>\n",
       "      <td>71.959875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.868917</td>\n",
       "      <td>55.847598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1         f2\n",
       "0  39.035944  73.376263\n",
       "1  56.427617  84.359787\n",
       "2  40.096580  71.701801\n",
       "3  47.581040  71.959875\n",
       "4   5.868917  55.847598"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demetr_good_feats.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_COMET_env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
