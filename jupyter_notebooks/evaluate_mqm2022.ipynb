{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed84aae",
   "metadata": {},
   "source": [
    "## Evaluation on MQM 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b5a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3deb22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    f = open (path, \"r\")\n",
    "    data = json.loads(f.read())\n",
    "    k = list(data.keys())[0]\n",
    "\n",
    "    src = []\n",
    "    mt = []\n",
    "    ref = []\n",
    "    COMET_score = []\n",
    "\n",
    "    for i in data[k]:\n",
    "        src.append(i['src'])\n",
    "        mt.append(i['mt'])\n",
    "        ref.append(i['ref'])\n",
    "        COMET_score.append(float(i['COMET']))\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    df = pd.DataFrame(data=np.array([src, mt, ref, COMET_score]).T, \n",
    "                      columns=['src', 'mt', 'ref', 'comet'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6e709",
   "metadata": {},
   "source": [
    "## en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47f4372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your home path\n",
    "home_path = '/home/glushkovato/robustness'\n",
    "\n",
    "conversation = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-de/conversation.csv')\n",
    "ecommerce = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-de/ecommerce.csv')\n",
    "news = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-de/news.csv')\n",
    "social = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-de/social.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9727ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "ecommerce\n",
      "news\n",
      "social\n"
     ]
    }
   ],
   "source": [
    "domain_names = ['conversation', 'ecommerce', 'news', 'social']\n",
    "domain_dfs = [conversation, ecommerce, news, social]\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"_src.txt\", \"w\") as f:\n",
    "        for i in domain.src.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"_mt.txt\", \"w\") as f:\n",
    "        for i in domain.mt.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"_ref.txt\", \"w\") as f:\n",
    "        for i in domain.ref.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"_score.txt\", \"w\") as f:\n",
    "        for i in domain.score.tolist():\n",
    "            print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0b8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    x = (x - mean)/std\n",
    "    return np.nan_to_num(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4225d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    return [mean, std]\n",
    "\n",
    "def apply_norm(mean, std, x):\n",
    "    xn = (np.array(x) - mean)/std\n",
    "    return np.array(xn)\n",
    "\n",
    "\n",
    "bleu_mean = 28.759837809513634\n",
    "bleu_std = 18.47107097319373\n",
    "chrf_mean = 58.992697061544284\n",
    "chrf_std = 14.286372518233168\n",
    "comet_mean = 0.46782439675103793\n",
    "comet_std = 0.37521584265953595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eee78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(df):\n",
    "    pearson = np.round(stats.pearsonr(df.comet, df.mqm), 3)\n",
    "    spearman = np.round(stats.spearmanr(df.comet, df.mqm), 3)\n",
    "    kendall = np.round(stats.kendalltau(df.comet, df.mqm), 3)\n",
    "    return pearson[0], spearman[0], kendall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffb60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations2(df):\n",
    "    pearson = np.round(stats.pearsonr(df.metric, df.mqm), 3)\n",
    "    spearman = np.round(stats.spearmanr(df.metric, df.mqm), 3)\n",
    "    kendall = np.round(stats.kendalltau(df.metric, df.mqm), 3)\n",
    "    return pearson[0], spearman[0], kendall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50494daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = ['24', '25', '29', '83']\n",
    "# 24 COMET\n",
    "# 25 COMET + aug\n",
    "# 29 COMET + SL-feats\n",
    "# 83 COMET + WL-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "605dac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.285 0.337 0.257\n",
      "ecommerce\n",
      "0.222 0.278 0.212\n",
      "news\n",
      "0.26 0.273 0.202\n",
      "social\n",
      "0.22 0.222 0.168\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"_chrf_scores.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        chrf_scores = [float(i) for i in f]\n",
    "    \n",
    "    domain_output = domain[['src', 'mt', 'ref', 'score']]\n",
    "    domain_output['metric'] = chrf_scores\n",
    "    domain_output['mqm'] = domain_output.score.tolist()\n",
    "    domain_output.mqm = domain_output.mqm.astype(float)\n",
    "\n",
    "    p, s, k = compute_correlations2(domain_output)\n",
    "    pearsons.append(p)\n",
    "    spearmans.append(s)\n",
    "    kendalls.append(k)\n",
    "    print(p, s, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7945a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  24\n",
      "conversation\n",
      "0.371 0.401 0.308\n",
      "ecommerce\n",
      "0.376 0.421 0.326\n",
      "news\n",
      "0.522 0.478 0.361\n",
      "social\n",
      "0.367 0.389 0.297\n",
      "\n",
      "model:  25\n",
      "conversation\n",
      "0.378 0.385 0.296\n",
      "ecommerce\n",
      "0.38 0.403 0.311\n",
      "news\n",
      "0.492 0.438 0.33\n",
      "social\n",
      "0.375 0.361 0.276\n",
      "\n",
      "model:  29\n",
      "conversation\n",
      "0.379 0.404 0.31\n",
      "ecommerce\n",
      "0.383 0.416 0.322\n",
      "news\n",
      "0.506 0.471 0.355\n",
      "social\n",
      "0.382 0.386 0.294\n",
      "\n",
      "model:  83\n",
      "conversation\n",
      "0.4 0.409 0.314\n",
      "ecommerce\n",
      "0.341 0.417 0.322\n",
      "news\n",
      "0.526 0.486 0.369\n",
      "social\n",
      "0.351 0.384 0.293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for v in versions:\n",
    "    print('model: ', v)\n",
    "    for i, domain in enumerate(domain_dfs):\n",
    "        print(domain_names[i])\n",
    "        name = domain_names[i]\n",
    "\n",
    "        path = home_path + '/robust_MT_evaluation/data/test/mqm2022/en-de/predictions/' + name + '_output_v' + v + 'e1.json'\n",
    "        domain_output = read_json(path)\n",
    "        domain_output['mqm'] = domain.score.astype(float).tolist()\n",
    "        domain_output.comet = domain_output.comet.astype(float)\n",
    "\n",
    "        p, s, k = compute_correlations(domain_output)\n",
    "        pearsons.append(p)\n",
    "        spearmans.append(s)\n",
    "        kendalls.append(k)\n",
    "        print(p, s, k)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecfc23de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.376 0.403 0.309\n",
      "ecommerce\n",
      "0.373 0.411 0.318\n",
      "news\n",
      "0.521 0.472 0.356\n",
      "social\n",
      "0.367 0.383 0.292\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "v = '24' # baseline COMET\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path_bleu = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"bleu_scores.txt\"\n",
    "    with open(path_bleu, \"r\") as f:\n",
    "        bleu_scores = [float(i) for i in f]\n",
    "        \n",
    "    path_chrf = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/en-de_\" + name + \"chrf_scores.txt\"\n",
    "    with open(path_chrf, \"r\") as f:\n",
    "        chrf_scores = [float(i) for i in f]\n",
    "        \n",
    "    path = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-de/predictions/' + name + '_output_v' + v + 'e1.json'\n",
    "    domain_output = read_json(path)\n",
    "    domain_output['mqm'] = domain.score.astype(float).tolist()\n",
    "    domain_output.comet = domain_output.comet.astype(float)\n",
    "    domain_output['bleu'] = bleu_scores\n",
    "    domain_output['chrf'] = chrf_scores\n",
    "    \n",
    "    # best weights based on kendall - computed over mqm 2021\n",
    "    a = 0.02512562814070352\n",
    "    b = 0.04522613065326633\n",
    "    c = 0.9296482412060302\n",
    "    \n",
    "\n",
    "    domain_output['ensemble_norm_w'] = np.mean([a*apply_norm(bleu_mean, bleu_std, domain_output['bleu'].tolist()), \n",
    "                                                b*apply_norm(chrf_mean, chrf_std, domain_output['chrf'].tolist()), \n",
    "                                                c*apply_norm(comet_mean, comet_std, domain_output['comet'].tolist())], axis=0)\n",
    "    \n",
    "    p = np.round(stats.pearsonr(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    s = np.round(stats.spearmanr(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    k = np.round(stats.kendalltau(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    print(p[0], s[0], k[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3dce7b",
   "metadata": {},
   "source": [
    "## en-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c9da064",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-ru/conversation.csv')\n",
    "ecommerce = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-ru/ecommerce.csv')\n",
    "news = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-ru/news.csv')\n",
    "social = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/en-ru/social.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ec75532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "ecommerce\n",
      "news\n",
      "social\n"
     ]
    }
   ],
   "source": [
    "domain_names = ['conversation', 'ecommerce', 'news', 'social']\n",
    "domain_dfs = [conversation, ecommerce, news, social]\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    with open(\"/home/glushkovato/robustness/COMET/data/test/testsets/data/mqm/en-ru/en-ru_\" + name + \"_src.txt\", \"w\") as f:\n",
    "        for i in domain.src.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(\"/home/glushkovato/robustness/COMET/data/test/testsets/data/mqm/en-ru/en-ru_\" + name + \"_mt.txt\", \"w\") as f:\n",
    "        for i in domain.mt.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(\"/home/glushkovato/robustness/COMET/data/test/testsets/data/mqm/en-ru/en-ru_\" + name + \"_ref.txt\", \"w\") as f:\n",
    "        for i in domain.ref.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(\"/home/glushkovato/robustness/COMET/data/test/testsets/data/mqm/en-ru/en-ru_\" + name + \"_score.txt\", \"w\") as f:\n",
    "        for i in domain.score.tolist():\n",
    "            print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "238d865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.155 0.183 0.14\n",
      "ecommerce\n",
      "0.249 0.276 0.202\n",
      "news\n",
      "0.169 0.171 0.125\n",
      "social\n",
      "0.213 0.212 0.152\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-ru/en-ru_\" + name + \"_bleu_scores.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        bleu_scores = [float(i) for i in f]\n",
    "    \n",
    "    domain_output = domain[['src', 'mt', 'ref', 'score']]\n",
    "    domain_output['metric'] = bleu_scores\n",
    "    domain_output['mqm'] = domain_output.score.tolist()\n",
    "    domain_output.mqm = domain_output.mqm.astype(float)\n",
    "\n",
    "    p, s, k = compute_correlations2(domain_output)\n",
    "    pearsons.append(p)\n",
    "    spearmans.append(s)\n",
    "    kendalls.append(k)\n",
    "    print(p, s, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e8ba3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.185 0.23 0.175\n",
      "ecommerce\n",
      "0.287 0.303 0.221\n",
      "news\n",
      "0.23 0.224 0.164\n",
      "social\n",
      "0.143 0.186 0.132\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-ru/en-ru_\" + name + \"_chrf_scores.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        chrf_scores = [float(i) for i in f]\n",
    "    \n",
    "    domain_output = domain[['src', 'mt', 'ref', 'score']]\n",
    "    domain_output['metric'] = chrf_scores\n",
    "    domain_output['mqm'] = domain_output.score.tolist()\n",
    "    domain_output.mqm = domain_output.mqm.astype(float)\n",
    "\n",
    "    p, s, k = compute_correlations2(domain_output)\n",
    "    pearsons.append(p)\n",
    "    spearmans.append(s)\n",
    "    kendalls.append(k)\n",
    "    print(p, s, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae42eff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  24\n",
      "conversation\n",
      "0.372 0.399 0.305\n",
      "ecommerce\n",
      "0.488 0.502 0.372\n",
      "news\n",
      "0.469 0.499 0.373\n",
      "social\n",
      "0.324 0.425 0.305\n",
      "\n",
      "model:  25\n",
      "conversation\n",
      "0.418 0.427 0.328\n",
      "ecommerce\n",
      "0.51 0.514 0.382\n",
      "news\n",
      "0.464 0.49 0.366\n",
      "social\n",
      "0.371 0.455 0.33\n",
      "\n",
      "model:  29\n",
      "conversation\n",
      "0.35 0.389 0.298\n",
      "ecommerce\n",
      "0.507 0.499 0.369\n",
      "news\n",
      "0.477 0.514 0.384\n",
      "social\n",
      "0.343 0.46 0.332\n",
      "\n",
      "model:  83\n",
      "conversation\n",
      "0.4 0.428 0.328\n",
      "ecommerce\n",
      "0.481 0.528 0.391\n",
      "news\n",
      "0.448 0.495 0.37\n",
      "social\n",
      "0.385 0.483 0.349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for v in versions:\n",
    "    print('model: ', v)\n",
    "    for i, domain in enumerate(domain_dfs):\n",
    "        print(domain_names[i])\n",
    "        name = domain_names[i]\n",
    "\n",
    "        path = home_path + '/robust_MT_evaluation/data/test/mqm2022/en-ru/predictions/' + name + '_output_v' + v + 'e1.json'\n",
    "        domain_output = read_json(path)\n",
    "        domain_output['mqm'] = domain.score.astype(float).tolist()\n",
    "        domain_output.comet = domain_output.comet.astype(float)\n",
    "\n",
    "        p, s, k = compute_correlations(domain_output)\n",
    "        pearsons.append(p)\n",
    "        spearmans.append(s)\n",
    "        kendalls.append(k)\n",
    "        print(p, s, k)\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63e5a3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.368 0.398 0.304\n",
      "ecommerce\n",
      "0.487 0.499 0.369\n",
      "news\n",
      "0.466 0.491 0.366\n",
      "social\n",
      "0.323 0.418 0.3\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "v = '24' # baseline model trained on 1720 original data\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path_bleu = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-ru/en-ru_\" + name + \"_bleu_scores.txt\"\n",
    "    with open(path_bleu, \"r\") as f:\n",
    "        bleu_scores = [float(i) for i in f]\n",
    "        \n",
    "    path_chrf = home_path + \"/robust_MT_evaluation/data/test/mqm2022/en-ru/en-ru_\" + name + \"_chrf_scores.txt\"\n",
    "    with open(path_chrf, \"r\") as f:\n",
    "        chrf_scores = [float(i) for i in f]\n",
    "        \n",
    "    path = home_path + '/robust_MT_evaluation/data/test/mqm2022/en-ru/predictions/' + name + '_output_v' + v + 'e1.json'\n",
    "    domain_output = read_json(path)\n",
    "    domain_output['mqm'] = domain.score.astype(float).tolist()\n",
    "    domain_output.comet = domain_output.comet.astype(float)\n",
    "    domain_output['bleu'] = bleu_scores\n",
    "    domain_output['chrf'] = chrf_scores\n",
    "    \n",
    "    # best weights based on kendall - computed over mqm 2021 \n",
    "    a = 0.02512562814070352\n",
    "    b = 0.04522613065326633\n",
    "    c = 0.9296482412060302\n",
    "    \n",
    "    # best weights based on pearson - computed over mqm 2021 (!)\n",
    "#     a = 0.07035175879396985\n",
    "#     b = 0.0\n",
    "#     c = 0.9296482412060302\n",
    "    \n",
    "    # best weights based on spearman - computed over mqm 2021\n",
    "#     a = 0.01507537688442211\n",
    "#     b = 0.05527638190954774\n",
    "#     c = 0.9296482412060302\n",
    "    \n",
    "\n",
    "\n",
    "    domain_output['ensemble_norm_w'] = np.mean([a*apply_norm(bleu_mean, bleu_std, domain_output['bleu'].tolist()), \n",
    "                                                b*apply_norm(chrf_mean, chrf_std, domain_output['chrf'].tolist()), \n",
    "                                                c*apply_norm(comet_mean, comet_std, domain_output['comet'].tolist())], axis=0)\n",
    "    \n",
    "    p = np.round(stats.pearsonr(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    s = np.round(stats.spearmanr(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    k = np.round(stats.kendalltau(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    print(p[0], s[0], k[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755eac7e",
   "metadata": {},
   "source": [
    "## zh-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ef49af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/zh-en/conversation.csv')\n",
    "ecommerce = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/zh-en/ecommerce.csv')\n",
    "news = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/zh-en/news.csv')\n",
    "social = pd.read_csv(home_path + '/robust_MT_evaluation/data/test/mqm2022/zh-en/social.csv')\n",
    "# social.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3e54733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "social.mt = social.mt.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98c3d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "ecommerce\n",
      "news\n",
      "social\n"
     ]
    }
   ],
   "source": [
    "domain_names = ['conversation', 'ecommerce', 'news', 'social']\n",
    "domain_dfs = [conversation, ecommerce, news, social]\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_src.txt\", \"w\") as f:\n",
    "        for i in domain.src.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_mt.txt\", \"w\") as f:\n",
    "        for i in domain.mt.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_ref.txt\", \"w\") as f:\n",
    "        for i in domain.ref.tolist():\n",
    "            print(i, file=f)\n",
    "\n",
    "    with open(home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_score.txt\", \"w\") as f:\n",
    "        for i in domain.score.tolist():\n",
    "            print(i, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0200a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.16 0.166 0.125\n",
      "ecommerce\n",
      "0.22 0.241 0.174\n",
      "news\n",
      "0.097 0.063 0.046\n",
      "social\n",
      "0.161 0.219 0.162\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path = home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_bleu_scores.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        bleu_scores = [float(i) for i in f]\n",
    "    \n",
    "    domain_output = domain[['src', 'mt', 'ref', 'score']]\n",
    "    domain_output['metric'] = bleu_scores\n",
    "    domain_output['mqm'] = domain_output.score.tolist()\n",
    "    domain_output.mqm = domain_output.mqm.astype(float)\n",
    "\n",
    "    p, s, k = compute_correlations2(domain_output)\n",
    "    pearsons.append(p)\n",
    "    spearmans.append(s)\n",
    "    kendalls.append(k)\n",
    "    print(p, s, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de5c74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.206 0.211 0.16\n",
      "ecommerce\n",
      "0.23 0.259 0.187\n",
      "news\n",
      "0.078 0.057 0.042\n",
      "social\n",
      "0.177 0.256 0.19\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path = home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_chrf_scores.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        chrf_scores = [float(i) for i in f]\n",
    "    \n",
    "    domain_output = domain[['src', 'mt', 'ref', 'score']]\n",
    "    domain_output['metric'] = chrf_scores\n",
    "    domain_output['mqm'] = domain_output.score.tolist()\n",
    "    domain_output.mqm = domain_output.mqm.astype(float)\n",
    "\n",
    "    p, s, k = compute_correlations2(domain_output)\n",
    "    pearsons.append(p)\n",
    "    spearmans.append(s)\n",
    "    kendalls.append(k)\n",
    "    print(p, s, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "200de84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  24\n",
      "conversation\n",
      "0.34 0.375 0.288\n",
      "ecommerce\n",
      "0.391 0.449 0.327\n",
      "news\n",
      "0.34 0.364 0.27\n",
      "social\n",
      "0.351 0.424 0.319\n",
      "\n",
      "model:  25\n",
      "conversation\n",
      "0.37 0.385 0.295\n",
      "ecommerce\n",
      "0.438 0.467 0.342\n",
      "news\n",
      "0.383 0.393 0.291\n",
      "social\n",
      "0.358 0.418 0.313\n",
      "\n",
      "model:  29\n",
      "conversation\n",
      "0.343 0.37 0.283\n",
      "ecommerce\n",
      "0.4 0.459 0.335\n",
      "news\n",
      "0.364 0.373 0.276\n",
      "social\n",
      "0.343 0.419 0.315\n",
      "\n",
      "model:  83\n",
      "conversation\n",
      "0.358 0.389 0.298\n",
      "ecommerce\n",
      "0.44 0.487 0.357\n",
      "news\n",
      "0.359 0.394 0.292\n",
      "social\n",
      "0.373 0.439 0.33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "\n",
    "for v in versions:\n",
    "    print('model: ', v)\n",
    "    for i, domain in enumerate(domain_dfs):\n",
    "        print(domain_names[i])\n",
    "        name = domain_names[i]\n",
    "\n",
    "        path = home_path + '/robust_MT_evaluation/data/test/mqm2022/zh-en/predictions/' + name + '_output_v' + v + 'e1.json'\n",
    "        domain_output = read_json(path)\n",
    "        domain_output['mqm'] = domain.score.astype(float).tolist()\n",
    "        domain_output.comet = domain_output.comet.astype(float)\n",
    "\n",
    "        p, s, k = compute_correlations(domain_output)\n",
    "        pearsons.append(p)\n",
    "        spearmans.append(s)\n",
    "        kendalls.append(k)\n",
    "        print(p, s, k)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e2a4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation\n",
      "0.338 0.369 0.283\n",
      "ecommerce\n",
      "0.39 0.446 0.325\n",
      "news\n",
      "0.332 0.351 0.26\n",
      "social\n",
      "0.346 0.422 0.317\n"
     ]
    }
   ],
   "source": [
    "pearsons = []\n",
    "spearmans = []\n",
    "kendalls = []\n",
    "v = '24' # baseline model trained on 1720 original data\n",
    "\n",
    "for i, domain in enumerate(domain_dfs):\n",
    "    print(domain_names[i])\n",
    "    name = domain_names[i]\n",
    "    \n",
    "    path_bleu = home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_bleu_scores.txt\"\n",
    "    with open(path_bleu, \"r\") as f:\n",
    "        bleu_scores = [float(i) for i in f]\n",
    "        \n",
    "    path_chrf = home_path + \"/robust_MT_evaluation/data/test/mqm2022/zh-en/zh-en_\" + name + \"_chrf_scores.txt\"\n",
    "    with open(path_chrf, \"r\") as f:\n",
    "        chrf_scores = [float(i) for i in f]\n",
    "        \n",
    "    path = home_path + '/robust_MT_evaluation/data/test/mqm2022/zh-en/predictions/' + name + '_output_v' + v + 'e1.json'\n",
    "    domain_output = read_json(path)\n",
    "    domain_output['mqm'] = domain.score.astype(float).tolist()\n",
    "    domain_output.comet = domain_output.comet.astype(float)\n",
    "    domain_output['bleu'] = bleu_scores\n",
    "    domain_output['chrf'] = chrf_scores\n",
    "    \n",
    "#     # best weights based on kendall - computed over mqm 2021\n",
    "    a = 0.02512562814070352\n",
    "    b = 0.04522613065326633\n",
    "    c = 0.9296482412060302\n",
    "    \n",
    "    # best weights based on pearson - computed over mqm 2021 (!)\n",
    "#     a = 0.07035175879396985\n",
    "#     b = 0.0\n",
    "#     c = 0.9296482412060302\n",
    "    \n",
    "#     # best weights based on spearman - computed over mqm 2021\n",
    "#     a = 0.01507537688442211\n",
    "#     b = 0.05527638190954774\n",
    "#     c = 0.9296482412060302\n",
    "\n",
    "\n",
    "    domain_output['ensemble_norm_w'] = np.mean([a*apply_norm(bleu_mean, bleu_std, domain_output['bleu'].tolist()), \n",
    "                                                b*apply_norm(chrf_mean, chrf_std, domain_output['chrf'].tolist()), \n",
    "                                                c*apply_norm(comet_mean, comet_std, domain_output['comet'].tolist())], axis=0)\n",
    "\n",
    "    \n",
    "    p = np.round(stats.pearsonr(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    s = np.round(stats.spearmanr(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    k = np.round(stats.kendalltau(domain_output.ensemble_norm_w, domain_output.mqm), 3)\n",
    "    print(p[0], s[0], k[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_COMET_env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
